{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example URL request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:8983/solr/tech_products/select?indent=true&q.op=OR&q=viewsonic&rows=20&useParams=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responseHeader': {'status': 0, 'QTime': 0, 'params': {'q': 'viewsonic', 'indent': 'true', 'q.op': 'OR', 'rows': '20', 'useParams': ''}}, 'response': {'numFound': 1, 'start': 0, 'numFoundExact': True, 'docs': [{'id': 'VA902B', 'name': 'ViewSonic VA902B - flat panel display - TFT - 19\"', 'manu': 'ViewSonic Corp.', 'manu_id_s': 'viewsonic', 'cat': ['electronics and stuff2'], 'features': ['19\" TFT active matrix LCD, 8ms response time, 1280 x 1024 native resolution'], 'weight': 190.4, 'price': 279.95, 'price_c': '279.95,USD', 'popularity': 6, 'inStock': True, 'store': '45.18814,-93.88541', '_version_': 1795237645975027712, 'manu_exact': 'ViewSonic Corp.', 'price_c____l_ns': 27995, 'name_exact': 'ViewSonic VA902B - flat panel display - TFT - 19\"'}]}}\n"
     ]
    }
   ],
   "source": [
    "response_json = response.json()\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the original crawled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(x):\n",
    "    temp = x \n",
    "    if (isinstance(x,str)):\n",
    "        temp = pd.to_datetime(temp,format= '%Y-%m-%d %H:%M:%S')\n",
    "    solr_date = temp.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    return solr_date\n",
    "\n",
    "def ProcessSheetName(sheet_name):\n",
    "    bk_name = sheet_name.split('(')[0]\n",
    "    # remove empty space at the back if any\n",
    "    if (bk_name[-1] == ' '):\n",
    "        bk_name = bk_name[:-1]\n",
    "    if (bk_name == 'GoT'):\n",
    "        bk_name = \"Game Of Thrones\"\n",
    "    elif (bk_name == 'LotR'):\n",
    "        bk_name = \"Lord of the Rings\"\n",
    "\n",
    "    return bk_name\n",
    "\n",
    "\n",
    "def ProcessData(info_name):\n",
    "    # info_name: Excel workbook name\n",
    "    # post_csv_name: name of the csv file containing the posts of the books\n",
    "    # comment_csv_name: name of the csv file containing the comments\n",
    "    info = pd.ExcelFile(info_name)\n",
    "    sheet_names = info.sheet_names\n",
    "    post_dataframe = pd.read_excel(info, sheet_names[0])\n",
    "    comment_dataframe = pd.read_excel(info, sheet_names[1])\n",
    "    # add the book name\n",
    "    bk_name_0 = ProcessSheetName(sheet_names[0])\n",
    "    bk_name_1 = ProcessSheetName(sheet_names[1])\n",
    "    bk_name_0 = pd.Series([bk_name_0] * len(post_dataframe.index))\n",
    "    bk_name_1 = pd.Series([bk_name_1] * len(comment_dataframe.index))\n",
    "    post_dataframe[\"book\"] = bk_name_0\n",
    "    comment_dataframe[\"book\"] = bk_name_1\n",
    "\n",
    "    for i in range(2, len(sheet_names)):\n",
    "        raw_dataframe = pd.read_excel(info, sheet_names[i])\n",
    "\n",
    "        # add book name\n",
    "        bk_name = ProcessSheetName(sheet_names[i])\n",
    "\n",
    "        bk_name = pd.Series([bk_name] * len(raw_dataframe.index))\n",
    "        raw_dataframe[\"book\"] = bk_name\n",
    "        # Every even-indexed sheet is a POST sheet\n",
    "        if (i%2 == 0):\n",
    "            post_dataframe = pd.concat([post_dataframe, raw_dataframe])\n",
    "        else:\n",
    "            comment_dataframe = pd.concat([comment_dataframe, raw_dataframe])\n",
    "\n",
    "    # label rows in the dataframe as POST or COMMENT for filtering when querying\n",
    "    title = pd.Series([\"POST\"] * len(post_dataframe.index))\n",
    "    post_dataframe[\"TYPE\"] = title\n",
    "    comment_title = pd.Series([\"COMMENT\"] * len(comment_dataframe.index))\n",
    "    comment_dataframe[\"TYPE\"] = comment_title\n",
    "\n",
    "    # Convert time into pdate format as required by Solr\n",
    "    post_created_utc = post_dataframe['created_utc']\n",
    "    post_created_utc = post_created_utc.apply(convert_time)\n",
    "    post_dataframe['created_utc'] = post_created_utc\n",
    "\n",
    "    comment_created_utc = comment_dataframe['created_utc']\n",
    "    comment_created_utc = comment_created_utc.apply(convert_time)\n",
    "    comment_dataframe['created_utc'] = comment_created_utc\n",
    "\n",
    "    return post_dataframe, comment_dataframe\n",
    "\n",
    "\n",
    "def AddCommentID(row):\n",
    "    if (row[\"post_id\"] not in post_id_dictionary.keys()):\n",
    "        post_id_dictionary[row[\"post_id\"]] = 1\n",
    "    else:\n",
    "        post_id_dictionary[row[\"post_id\"]] += 1\n",
    "        \n",
    "    return row[\"post_id\"] + \"_\" + str(post_id_dictionary[row[\"post_id\"]])\n",
    "        \n",
    "def AddCommentNum(row):\n",
    "    if (row[\"post_id\"] not in post_id_dictionary.keys()):\n",
    "        post_id_dictionary[row[\"post_id\"]] = 1\n",
    "    else:\n",
    "        post_id_dictionary[row[\"post_id\"]] += 1\n",
    "        \n",
    "    return post_id_dictionary[row[\"post_id\"]]\n",
    "\n",
    "def ProcessCommentSheet(sheet_name):\n",
    "    global post_id_dictionary\n",
    "    post_id_dictionary = {}\n",
    "    comment_df = pd.read_csv(sheet_name + \".csv\")\n",
    "    comment_df[\"id\"] = comment_df.apply(AddCommentID, axis=1)\n",
    "\n",
    "    # bring id column to the front\n",
    "    cols = comment_df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    comment_df = comment_df[cols]\n",
    "    \n",
    "    # add comment num   \n",
    "    post_id_dictionary = {}\n",
    "    comment_df[\"comment_num\"] = comment_df.apply(AddCommentNum, axis=1)\n",
    "    comment_df.to_csv(sheet_name + \"_process.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function to process the initial data sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessDataInitial(info_name):\n",
    "    # info_name: Excel workbook name\n",
    "    # post_csv_name: name of the csv file containing the posts of the books\n",
    "    # comment_csv_name: name of the csv file containing the comments\n",
    "    info = pd.ExcelFile(info_name)\n",
    "    sheet_names = info.sheet_names\n",
    "\n",
    "    # for labelling categories later\n",
    "    fantasy_cats = [\"Game Of Thrones\", \"Lord of the Rings\", \"Harry Potter\"]\n",
    "\n",
    "    post_dataframe = pd.read_excel(info, sheet_names[0])\n",
    "    comment_dataframe = pd.read_excel(info, sheet_names[1])\n",
    "    # add the book name\n",
    "    bk_name_0 = ProcessSheetName(sheet_names[0])\n",
    "    bk_name_1 = ProcessSheetName(sheet_names[1])\n",
    "\n",
    "    # label categories\n",
    "    if (bk_name_0 in fantasy_cats):\n",
    "        cat = pd.Series([\"Fantasy\"] * len(post_dataframe.index))\n",
    "        post_dataframe[\"category\"] = cat\n",
    "    else:\n",
    "        cat = pd.Series([\"Romance\"] * len(post_dataframe.index))\n",
    "        post_dataframe[\"category\"] = cat\n",
    "\n",
    "    if (bk_name_1 in fantasy_cats):\n",
    "        cat = pd.Series([\"Fantasy\"] * len(comment_dataframe.index))\n",
    "        comment_dataframe[\"category\"] = cat\n",
    "    else:\n",
    "        cat = pd.Series([\"Romance\"] * len(comment_dataframe.index))\n",
    "        comment_dataframe[\"category\"] = cat\n",
    "        \n",
    "    bk_name_0 = pd.Series([bk_name_0] * len(post_dataframe.index))\n",
    "    bk_name_1 = pd.Series([bk_name_1] * len(comment_dataframe.index))\n",
    "    post_dataframe[\"book\"] = bk_name_0\n",
    "    comment_dataframe[\"book\"] = bk_name_1\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(2, len(sheet_names)):\n",
    "        raw_dataframe = pd.read_excel(info, sheet_names[i])\n",
    "\n",
    "        # add book name\n",
    "        bk_name = ProcessSheetName(sheet_names[i])\n",
    "\n",
    "        # add category\n",
    "        if (bk_name in fantasy_cats):\n",
    "            cat = pd.Series([\"Fantasy\"] * len(raw_dataframe.index))\n",
    "            raw_dataframe[\"category\"] = cat\n",
    "        else:\n",
    "            cat = pd.Series([\"Romance\"] * len(raw_dataframe.index))\n",
    "            raw_dataframe[\"category\"] = cat\n",
    "\n",
    "        # add book name\n",
    "        bk_name = pd.Series([bk_name] * len(raw_dataframe.index))\n",
    "        raw_dataframe[\"book\"] = bk_name\n",
    "        \n",
    "\n",
    "        # Every even-indexed sheet is a POST sheet\n",
    "        if (i%2 == 0):\n",
    "            post_dataframe = pd.concat([post_dataframe, raw_dataframe])\n",
    "        else:\n",
    "            comment_dataframe = pd.concat([comment_dataframe, raw_dataframe])\n",
    "\n",
    "    # label rows in the dataframe as POST or COMMENT for filtering when querying\n",
    "    title = pd.Series([\"POST\"] * len(post_dataframe.index))\n",
    "    post_dataframe[\"TYPE\"] = title\n",
    "    comment_title = pd.Series([\"COMMENT\"] * len(comment_dataframe.index))\n",
    "    comment_dataframe[\"TYPE\"] = comment_title\n",
    "\n",
    "    # Convert time into pdate format as required by Solr\n",
    "    post_created_utc = post_dataframe['created_utc']\n",
    "    post_created_utc = post_created_utc.apply(convert_time)\n",
    "    post_dataframe['created_utc'] = post_created_utc\n",
    "\n",
    "    comment_created_utc = comment_dataframe['created_utc']\n",
    "    comment_created_utc = comment_created_utc.apply(convert_time)\n",
    "    comment_dataframe['created_utc'] = comment_created_utc\n",
    "\n",
    "    return post_dataframe, comment_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the first two sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df, comment_df = ProcessDataInitial(\"Info.xlsx\")\n",
    "post_df.to_csv(\"post.csv\", index=False)\n",
    "comment_df.to_csv(\"comment.csv\", index=False)\n",
    "\n",
    "ProcessCommentSheet(\"comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Book Data/\"\n",
    "excel_names = [\"Action Books.xlsx\", \"Comedy Books.xlsx\", \"Fantasy Books.xlsx\", \"Horror Books.xlsx\", \"Mystery Books.xlsx\"]\n",
    "comment_names = []\n",
    "\n",
    "\n",
    "for i in excel_names:\n",
    "    post_df, comment_df = ProcessData(data_dir+i)\n",
    "\n",
    "    # Adding category\n",
    "    cat_name_post = pd.Series([i.split()[0]] * len(post_df.index))\n",
    "    cat_name_comment = pd.Series([i.split()[0]] * len(comment_df.index))\n",
    "    post_df['category'] = cat_name_post\n",
    "    comment_df['category'] = cat_name_comment\n",
    "\n",
    "    # Saving csv\n",
    "    post_df.to_csv(i.split()[0] + \"_post.csv\", index=False)\n",
    "    comment_df.to_csv(i.split()[0] + \"_comment.csv\", index=False)\n",
    "\n",
    "    # Record comment sheets to process comment id and num later\n",
    "    comment_names.append(i.split()[0] + \"_comment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Comment ID and Comment num to comment data sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_dictionary = {}\n",
    "for i in comment_names:\n",
    "    ProcessCommentSheet(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action_Dune_analyzed_reviews.xlsx\n",
      "Action_Jurassic Park_analyzed_reviews.xlsx\n",
      "Action_Ready Player One_analyzed_reviews.xlsx\n",
      "Action_The Hunger Games_analyzed_reviews.xlsx\n",
      "Action_The Maze Runner_analyzed_reviews.xlsx\n",
      "Comedy_Catch-22_analyzed_reviews.xlsx\n",
      "Comedy_Confed of Dunces_analyzed_reviews.xlsx\n",
      "Comedy_Good Omens_analyzed_reviews.xlsx\n",
      "Comedy_The Catcher in the Rye_analyzed_reviews.xlsx\n",
      "Comedy_The Idiot_analyzed_reviews.xlsx\n",
      "Fantasy_Eragon_analyzed_reviews.xlsx\n",
      "Fantasy_Narnia_analyzed_reviews.xlsx\n",
      "Fantasy_The Hobbit_analyzed_reviews.xlsx\n",
      "Fantasy_The Last Wish_analyzed_reviews.xlsx\n",
      "Fantasy_The Royal Ranger_analyzed_reviews.xlsx\n",
      "Horror_Dracula_analyzed_reviews.xlsx\n",
      "Horror_Frankenstein_analyzed_reviews.xlsx\n",
      "Horror_THe Exorcist_analyzed_reviews.xlsx\n",
      "Horror_The Housemaid_analyzed_reviews.xlsx\n",
      "Horror_The Shining_analyzed_reviews.xlsx\n",
      "Mystery_Devil in the White City_analyzed_reviews.xlsx\n",
      "Mystery_Gone Girl_analyzed_reviews.xlsx\n",
      "Mystery_Rebecca_analyzed_reviews.xlsx\n",
      "Mystery_The Maid_analyzed_reviews.xlsx\n",
      "Mystery_The Secret History_analyzed_reviews.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
